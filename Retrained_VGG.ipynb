{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32788936",
   "metadata": {},
   "source": [
    "## Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8484be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                           # For file processing.\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory values\n",
    "#split_size=0.1\n",
    "#print('split_size =',split_size)\n",
    "\n",
    "# Get the current directory.\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# the data will be written to a working directory.\n",
    "working_dir    = os.path.join(current_dir,'data')\n",
    "train_data_dir = os.path.join(working_dir,'Train')\n",
    "test_data_dir  = os.path.join(working_dir,'Test')\n",
    "meta_data_dir  = os.path.join(working_dir,'Meta')\n",
    "\n",
    "print('current_dir      = ',current_dir)\n",
    "print('working_dir      = ',working_dir)\n",
    "print('train_data_dir   = ',train_data_dir)\n",
    "print('test_data_dir    = ',test_data_dir)\n",
    "print('meta_data_dir    = ',meta_data_dir)\n",
    "meta_csv_file = (os.path.join(working_dir,'meta.csv'))\n",
    "print('meta_csv_file    = ',meta_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283a6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# The default input size for this model is 224x224.\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "dim = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=90, \n",
    "                                     brightness_range=[0.1, 0.7],\n",
    "                                     width_shift_range=0.5, \n",
    "                                     height_shift_range=0.5,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True,\n",
    "                                     validation_split=0.15,\n",
    "                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8779d",
   "metadata": {},
   "source": [
    "### Create a training data generator to resize the images to the VGG16 expected size and to split the traininf data into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f655bb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m033\\MSc\\MachineLearning\\IndividualAssignment\\data\\Train\n",
      "Found 33337 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "print(train_data_dir)\n",
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='training',\n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True,\n",
    "                                               seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30096e11",
   "metadata": {},
   "source": [
    "### Create a training data generator to resize the images to the VGG16 expected size and to split the traininf data into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1ca671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5872 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "validgen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f93a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12630 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "                                             class_mode=None,\n",
    "                                             classes=class_subset,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b62539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b77a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x1e000297ee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "n_classes=10\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, n_classes, optim_1, fine_tune=0)\n",
    "vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ffb502b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'livelossplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d3b740fa0686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlotLossesCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'livelossplot'"
     ]
    }
   ],
   "source": [
    "from livelossplot.inputs.keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35276ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3ff0fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'livelossplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0021c3f3cc5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlotLossesCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_loss_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlotLossesCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ModelCheckpoint callback - save best weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'livelossplot'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plot_loss_1 = PlotLossesCallback()\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249b305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
